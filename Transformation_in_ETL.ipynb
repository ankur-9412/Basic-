{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EqgPu8-idtm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : Define Data Transformation in ETL and explain why it is important\n",
        "\n",
        "```\n",
        "Data Transformation is the process of converting raw data from source systems into a clean, structured, and meaningful format during the ETL (Extract, Transform, Load) process so that it can be properly stored and analyzed in a data warehouse.\n",
        "\n",
        "Why Data Transformation is Important:\n",
        "\n",
        "1. Improves Data Quality\n",
        "   * Removes duplicates, null values, and inconsistencies\n",
        "   * Ensures accurate and reliable data\n",
        "\n",
        "2. Makes Data Consistent\n",
        "   * Converts different formats (dates, currencies, units) into a standard form\n",
        "   * Aligns data from multiple sources\n",
        "\n",
        "3. Supports Business Analysis\n",
        "\n",
        "   * Converts raw data into business-friendly metrics (e.g., total sales, average revenue)\n",
        "   * Makes reporting and decision-making easier\n",
        "\n",
        "4. Ensures Data Integrity\n",
        "   * Applies rules and validations to maintain correctness\n",
        "   * Prevents wrong or misleading insights\n",
        "\n",
        "5. Improves Query Performance\n",
        "   * Aggregated and structured data reduces processing time during analysis\n",
        "\n",
        "```\n",
        "Question 2 : List any four common activities involved in Data Cleaning.\n",
        "\n",
        "```\n",
        "1. Removing Duplicate Records\n",
        "   * Identifies and deletes repeated entries to avoid incorrect analysis.\n",
        "2. Handling Missing Values\n",
        "   * Filling missing data using mean/median/mode or removing incomplete records.\n",
        "3. Correcting Inconsistent Data\n",
        "   * Fixing spelling mistakes, wrong formats (dates, numbers), and mismatched values.\n",
        "4. Validating Data Accuracy\n",
        "  * Checking data against business rules (e.g., age cannot be negative, price > 0).\n",
        "\n",
        "```\n",
        "Question 3 : What is the difference between Normalization and Standardization?\n",
        "\n",
        "```\n",
        "| Basis                  | Normalization                                                   | Standardization                                                 |\n",
        "| ---------------------- | --------------------------------------------------------------- | --------------------------------------------------------------- |\n",
        "| **Meaning**            | Scales data to a fixed range, usually **0 to 1**                | Scales data to have **mean = 0** and **standard deviation = 1** |\n",
        "| **Formula**            | ( (x - min) / (max - min) )                                     | ( (x - \\mu) / \\sigma )                                          |\n",
        "| **Effect of Outliers** | Highly affected by outliers                                     | Less affected compared to normalization                         |\n",
        "| **Use Case**           | When data has **known bounds** or for distance-based algorithms | When data follows or is close to a **normal distribution**      |\n",
        "| **Common Usage**       | Min-Max Scaling                                                 | Z-Score Scaling                                                 |\n",
        "\n",
        "```\n",
        "Question 4 : A dataset has missing values in the “Age” column. Suggest two techniques to handle this and\n",
        "explain when they should be used.\n",
        "\n",
        "```\n",
        "1. Mean / Median Imputation\n",
        "   * Replace missing age values with the mean or median age of the dataset.\n",
        "   * When to use:\n",
        "       * When the number of missing values is small\n",
        "       * Median is preferred if the data has outliers\n",
        "       * Mean is suitable when data is normally distributed\n",
        "\n",
        "2. Deleting Records with Missing Values\n",
        "   * Remove rows where the Age value is missing.\n",
        "   * When to use:  \n",
        "      * When missing values are very few  \n",
        "      * When the dataset is large, and deleting rows does not affect analysis\n",
        "```\n",
        "Question 5 : Convert the following inconsistent “Gender” entries into a standardized format (“Male”, “Female”)\n",
        "[\"M\", \"male\", \"F\", \"Female\", \"MALE\", \"f\"]\n",
        "\n",
        "\n",
        "```\n",
        "[\"M\", \"male\", \"F\", \"Female\", \"MALE\", \"f\"]\n",
        "\n",
        "[\"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Female\"]\n",
        "\n",
        "```\n",
        "Question 6 : What is One-Hot Encoding? Give an example with the categories: “Red, Blue, Green”.\n",
        "\n",
        "\n",
        "```\n",
        "One-Hot Encoding is a technique used to convert categorical data into numerical (binary) form so that it can be used by machine learning algorithms.\n",
        "\n",
        "| Color | Red | Blue | Green |\n",
        "| ----- | --- | ---- | ----- |\n",
        "| Red   | 1   | 0    | 0     |\n",
        "| Blue  | 0   | 1    | 0     |\n",
        "| Green | 0   | 0    | 1     |\n",
        "\n",
        "Each category is represented by a separate column with a value of 1 or 0.\n",
        "```\n",
        "Question 7 : Explain the difference between Data Integration and Data Mapping in ETL.\n",
        "\n",
        "\n",
        "```\n",
        "* Data Integration is the process of combining data from multiple sources into a single, unified dataset.  \n",
        "* Data Mapping is the process of defining how data fields from a source system correspond to fields in a target system.\n",
        "\n",
        "Key Difference:\n",
        "Data Integration focuses on combining data, while Data Mapping focuses on field-to-field relationships.\n",
        "```\n",
        "Question 8 : Explain why Z-score Standardization is preferred over Min-Max Scaling when outliers exist.\n",
        "\n",
        "\n",
        "```\n",
        "Z-score standardization is preferred over Min-Max scaling when outliers exist because it uses the mean and standard deviation, which reduces the impact of extreme values.\n",
        "\n",
        "Min-Max scaling depends on the minimum and maximum values, so outliers can significantly distort the scaled data.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TiX6t0lQifb2"
      }
    }
  ]
}