{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3lwsW5Unyz1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: Define Data Quality in the context of ETL pipelines. Why is it more than just data cleaning?\n",
        "\n",
        "\n",
        "```\n",
        "In ETL pipelines, Data Quality refers to the degree to which data is accurate, complete, consistent, valid, and reliable throughout extraction, transformation, and loading.\n",
        "It is more than data cleaning because it also involves validation, standardization, rule enforcement, and consistency checks, ensuring data is fit for business and analytical use.\n",
        "```\n",
        "Question 2: Explain why poor data quality leads to misleading dashboards and incorrect decisions.\n",
        "\n",
        "\n",
        "```\n",
        "Poor data quality leads to misleading dashboards because incorrect, incomplete, or inconsistent data results in wrong KPIs, inaccurate trends, and unreliable metrics.\n",
        "As a result, decision-makers may take actions based on false insights, leading to financial loss or poor strategic decisions.\n",
        "```\n",
        "Question 3: What is duplicate data? Explain three causes in ETL pipelines.\n",
        "\n",
        "\n",
        "```\n",
        "Duplicate data refers to multiple records representing the same real-world entity.\n",
        "\n",
        "Three causes in ETL pipelines:\n",
        "\n",
        "1. Data coming from multiple sources without proper matching\n",
        "\n",
        "2. Missing or weak primary key validation\n",
        "\n",
        "3. Incorrect incremental or batch load logic\n",
        "\n",
        "\n",
        "```\n",
        "Question 4: Differentiate between exact, partial, and fuzzy duplicates.\n",
        "\n",
        "\n",
        "```\n",
        "* Exact duplicates: All fields are identical\n",
        "* Partial duplicates: Some key fields match\n",
        "* Fuzzy duplicates: Records are similar but not exactly the same (e.g., spelling variations).\n",
        "```\n",
        "Question 5: Why should data validation be performed during transformation rather than after loading?\n",
        "\n",
        "\n",
        "```\n",
        "Data validation should be performed during transformation because it allows errors to be detected early, prevents invalid data from entering the target system, reduces rework costs, and maintains data integrity.\n",
        "```\n",
        "Question 6: Explain how business rules help in validating data accuracy. Give an example.\n",
        "\n",
        "\n",
        "```\n",
        "Business rules define acceptable conditions for data values.\n",
        "By applying these rules during ETL, data accuracy can be validated.\n",
        "\n",
        "Example:\n",
        "A business rule may state that customer age must be 18 or above.\n",
        "Any record violating this rule is rejected or flagged during transformation.\n",
        "```\n",
        "Question 7 : Write an SQL query on Sales_Transactions to list all duplicate keys and their counts using the\n",
        "business key (Customer_ID + Product_ID + Txn_Date + Txn_Amount )\n",
        "\n",
        "\n",
        "```\n",
        "SELECT\n",
        "    Customer_ID,\n",
        "    Product_ID,\n",
        "    Txn_Date,\n",
        "    Txn_Amount,\n",
        "    COUNT(*) AS duplicate_count\n",
        "FROM Sales_Transactions\n",
        "GROUP BY\n",
        "    Customer_ID,\n",
        "    Product_ID,\n",
        "    Txn_Date,\n",
        "    Txn_Amount\n",
        "HAVING COUNT(*) > 1;\n",
        "\n",
        "```\n",
        "Question 8: Identify Sales_Transactions.Customer_ID values that violate referential integrity when joined with\n",
        "Customers_Master and write a query to detect such violations.\n",
        "\n",
        "\n",
        "```\n",
        "SELECT DISTINCT st.Customer_ID\n",
        "FROM Sales_Transactions st\n",
        "LEFT JOIN Customers_Master cm\n",
        "    ON st.Customer_ID = cm.CustomerID\n",
        "WHERE cm.CustomerID IS NULL;\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_R97ZtaVn1Zm"
      }
    }
  ]
}